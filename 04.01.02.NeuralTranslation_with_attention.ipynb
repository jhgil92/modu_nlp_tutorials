{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Translation with Attentional seq2seq  \n",
    "\n",
    "지난 실습에서는 seq2seq를 사용하여 날짜언어->날짜포맷 으로의 번역을 시도해 보았습니다.  \n",
    "이번 실습에서는 동일한 task를 attention 개념이 포함된 seq2seq 모델을 이용해 다시 처리해 보겠습니다.\n",
    "\n",
    "(참고)  \n",
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html  \n",
    "https://medium.com/datalogue/attention-in-keras-1892773a4f22  \n",
    "https://medium.com/@jbetker/implementing-seq2seq-with-attention-in-keras-63565c8e498c  \n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html  \n",
    "https://github.com/neonbjb/ml-notebooks/blob/master/keras-seq2seq-with-attention/keras_translate_notebook.ipynb  \n",
    "https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "# Start by importing all the things we'll need.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Dot, Concatenate, Input, Activation, LSTM, Dense, Embedding, CuDNNLSTM, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# This enables the Jupyter backend on some matplotlib installations.\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1984)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 포맷의 데이터 경로를 지정합니다.\n",
    "train_dataset_filepath = 'datasets/nmt_date/nmt_date_train.csv'\n",
    "test_dataset_filepath = 'datasets/nmt_date/nmt_date_test.csv'\n",
    "df = pd.read_csv(train_dataset_filepath, header=None, names=['X', 'Y'])\n",
    "x_corpus = df.iloc[:,0] \n",
    "y_corpus = df.iloc[:,1] \n",
    "x_corpus_list = x_corpus.values.tolist()\n",
    "y_corpus_list = y_corpus.values.tolist()\n",
    "x_char_list = np.concatenate([list(tuple(x)) for x in x_corpus_list], axis=0)\n",
    "y_char_list = np.concatenate([list(tuple(y)) for y in y_corpus_list], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_x = Counter(x_char_list)\n",
    "counter_y = Counter(y_char_list)\n",
    "x_vocab = ['PAD', 'BOS', 'EOS', 'UNK']\n",
    "x_vocab = x_vocab + list(Counter(dict(counter_x.most_common())))\n",
    "y_vocab = ['PAD', 'BOS', 'EOS', 'UNK']\n",
    "y_vocab = y_vocab + list(Counter(dict(counter_y.most_common())))\n",
    "idx2char_x = dict(enumerate(x_vocab))\n",
    "char2idx_x = {char:index for index, char in enumerate(x_vocab)}\n",
    "idx2char_y = dict(enumerate(y_vocab))\n",
    "char2idx_y = {char:index for index, char in enumerate(y_vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_to_indexed_corpus(corpus, char2idx):\n",
    "    indexed_corpus = [char2idx['BOS']]\n",
    "    indexed_corpus = indexed_corpus + [char2idx[char] if char in char2idx else char2idx['UNK'] for char in tuple(corpus)]\n",
    "    indexed_corpus = indexed_corpus + [char2idx_x['EOS']]\n",
    "    return indexed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_x_corpus_list = []\n",
    "for doc in x_corpus_list:\n",
    "    indexed_x_corpus_list.append(convert_sentence_to_indexed_corpus(doc, char2idx_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_y_corpus_list = []\n",
    "for doc in y_corpus_list:\n",
    "    indexed_y_corpus_list.append(convert_sentence_to_indexed_corpus(doc, char2idx_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_x_corpus_length = max([len(doc) for doc in indexed_x_corpus_list])\n",
    "max_y_corpus_length = max([len(doc) for doc in indexed_y_corpus_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 68)\n",
      "(500000, 12)\n",
      "(500000, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.keras.preprocessing.sequence.pad_sequences(indexed_x_corpus_list, maxlen=max_x_corpus_length, padding=\"post\")\n",
    "output_data = tf.keras.preprocessing.sequence.pad_sequences(indexed_y_corpus_list, maxlen=max_y_corpus_length, padding=\"post\")\n",
    "teacher_data = output_data\n",
    "\n",
    "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
    "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=max_y_corpus_length, padding=\"post\")\n",
    "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
    "\n",
    "print(input_data.shape)\n",
    "print(teacher_data.shape)\n",
    "print(target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(x_corpus_list)\n",
    "BATCH_SIZE = 32\n",
    "embedding_dim = 16\n",
    "units = 32\n",
    "x_vocab_size = len(idx2char_y)\n",
    "y_vocab_size = len(idx2char_y)\n",
    "len_input = max_x_corpus_length\n",
    "len_target = max_y_corpus_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Attentional seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Encoder layers first.\n",
    "encoder_inputs = Input(shape=(len_input,))\n",
    "encoder_emb = Embedding(input_dim=x_vocab_size, output_dim=embedding_dim)\n",
    "# encoder_lstm = CuDNNLSTM(units=units, return_sequences=True, return_state=True)\n",
    "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True), merge_mode='concat')\n",
    "\n",
    "encoder_outputs = encoder_lstm(encoder_emb(encoder_inputs))\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(64)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create the Decoder layers.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_emb = Embedding(input_dim=y_vocab_size, output_dim=embedding_dim)\n",
    "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
    "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs))#, initial_state=encoder_states)\n",
    "decoder_lstm_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context and Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(128)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention = K.dot([decoder_lstm_out, encoder_outputs], axes=[2, 2])\n",
    "attention = Dot(axes=[2, 2])([decoder_lstm_out, encoder_outputs])\n",
    "attention = Activation('softmax')(attention)\n",
    "\n",
    "# context = K.dot([attention, encoder_outputs], axes=[2,1])\n",
    "context = Dot(axes=[2, 1])([attention, encoder_outputs])\n",
    "# context.shape\n",
    "decoder_combined_context = Concatenate(axis=2)([context, decoder_lstm_out])\n",
    "decoder_combined_context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = TimeDistributed(Dense(units, activation=\"tanh\"))(decoder_combined_context) # equation (5) of the paper\n",
    "output = TimeDistributed(Dense(y_vocab_size, activation=\"softmax\"))(output) # equation (6) of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 68)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 16)     240         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 68, 16)       240         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)        [(None, None, 64), ( 20992       embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 68, 64)       12800       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, None, 68)     0           cu_dnnlstm_7[0][0]               \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, 68)     0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, None, 64)     0           activation_6[0][0]               \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 128)    0           dot_14[0][0]                     \n",
      "                                                                 cu_dnnlstm_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 32)     4128        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 15)     495         time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 38,895\n",
      "Trainable params: 38,895\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=[output])\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400000 samples, validate on 100000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\uhmpp\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\uhmpp\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "400000/400000 [==============================] - 180s 450us/sample - loss: 0.4057 - sparse_categorical_accuracy: 0.8336 - val_loss: 0.2366 - val_sparse_categorical_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "history = model.fit([input_data, teacher_data], target_data,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 epochs=epochs,\n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence):\n",
    "    pre = convert_sentence_to_indexed_corpus(sentence, char2idx_x)\n",
    "    vec = np.zeros(len_input)\n",
    "    for i,w in enumerate(pre):\n",
    "        vec[i] = w\n",
    "    return vec\n",
    "\n",
    "def generate(input_sentence):\n",
    "    encoder_input = sentence_to_vector(input_sentence)\n",
    "    # Reshape so we can use the encoder model. New shape=[samples,sequence length]\n",
    "    encoder_input = encoder_input.reshape(1,len(encoder_input))\n",
    "\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), len_target))\n",
    "    decoder_input[:,0] = char2idx_y['BOS']\n",
    "    for i in range(1, len_target):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "        if output[:,i] == char2idx_y['EOS']:\n",
    "            break\n",
    "    return decoder_input[:,1:]\n",
    "\n",
    "def decode(idx2char, sequence):\n",
    "    text = \"\"\n",
    "    for i in sequence:\n",
    "        if i == char2idx_y['PAD'] or i == char2idx_y['EOS']:\n",
    "            break\n",
    "        text += idx2char[i]\n",
    "    return text\n",
    "\n",
    "def translate(input_sentence):\n",
    "    decoder_output = generate(input_sentence)\n",
    "    print(decoder_output)\n",
    "    return decode(idx2char_y, decoder_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7. 6. 8. 4. 5. 4. 6. 2. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'219-0-1'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"June 11th, 2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
